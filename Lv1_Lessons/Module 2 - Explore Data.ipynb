{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2 - Explore Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries have pre-defined code for other functions that are not included in basic Python. Once a library has been imported, any of its functions can be used throughout the entire notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### csv files\n",
    "\n",
    "Stands for \"comma separated values\"; it is a plain text file where each value is separated by some delimiter (usually commas but can be tabs, semicolons, spaces, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load csv file data with headers\n",
    "\n",
    "location = \"datasets/smallgradesh.csv\"\n",
    "df = pd.read_csv(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()\n",
    "#df.head?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data without headers\n",
    "\n",
    "location2 = \"datasets/smallgrades.csv\"\n",
    "df_nohead = pd.read_csv(location2, header=None) #try w/o header=None\n",
    "df_nohead.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add headers during data load\n",
    "\n",
    "df_during = pd.read_csv(location2, names=['Name', 'Grade'])\n",
    "df_during.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#add headers after data load\n",
    "\n",
    "df_nohead.columns = ['Name', 'Grade']\n",
    "df_nohead.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data\n",
    "\n",
    "names = ['Bob','Jessica','Mary','John','Mel']\n",
    "grades = [76,95,77,78,99]\n",
    "GradeList = list(zip(names,grades))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export csv files\n",
    "\n",
    "df = pd.DataFrame(data = GradeList, columns=['Names','Grades'])\n",
    "df.to_csv('studentgrades.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Excel file\n",
    "\n",
    "location = \"datasets/gradedata.xlsx\"\n",
    "df = pd.read_excel(location) #overwrites the info from the df variable in the examples above\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dataframe as Excel file\n",
    "\n",
    "#using GradeList from above\n",
    "names = ['Bob','Jessica','Mary','John','Mel']\n",
    "grades = [76,95,77,78,99]\n",
    "GradeList = list(zip(names,grades))\n",
    "\n",
    "df = pd.DataFrame(data = GradeList, columns=['Names','Grades'])\n",
    "writer = pd.ExcelWriter('dataframe.xlsx', engine='xlsxwriter')\n",
    "df.to_excel(writer, sheet_name='Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiple sheets\n",
    "\n",
    "df = pd.DataFrame(data = GradeList, columns=['Names','Grades'])\n",
    "writer = pd.ExcelWriter('dataframe.xlsx', engine='xlsxwriter')\n",
    "df.to_excel(writer, sheet_name='Sheet1')\n",
    "df.to_excel(writer, sheet_name='Sheet2')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load gradedata.csv file\n",
    "\n",
    "location = \"datasets/gradedata.csv\"\n",
    "df = pd.read_csv(location)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the column names in the dataset\n",
    "df.columns\n",
    "#or print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the data type of each column\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of non-NA values\n",
    "#len(df) would count rows including NA values\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hours'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hours'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['hours'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hours'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hours'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hours'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hours'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard deviation\n",
    "df['hours'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#descriptive statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doesn't do anything on its own\n",
    "df.groupby('gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a stats or math function to it\n",
    "df['hours'].groupby(df['gender']).mean()\n",
    "\n",
    "#mean of multiple columns\n",
    "#df[['hours', 'exercise']].groupby(df['gender']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use two columns to groupby\n",
    "df.groupby(['gender', 'age']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot table default function is mean\n",
    "pd.pivot_table(df, index=['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(df, values=['hours'], index=['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique values in a column\n",
    "df['age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#find missing values\n",
    "filename = \"datasets/gradedatamissing.csv\"\n",
    "df_missing = pd.read_csv(filename)\n",
    "\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total missing values\n",
    "df_missing.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#show rows with missing values\n",
    "missing = df_missing['exercise'].isnull()\n",
    "#missing will only show True/False values\n",
    "df_missing.loc[missing]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Jessica','John','Bob','Jessica','Mary','John','Mel','Mel']\n",
    "grades = [95,78,76,95,77,78,99,100]\n",
    "GradeList = list(zip(names,grades))\n",
    "df = pd.DataFrame(data = GradeList, columns=['Names', 'Grades'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boolean values for if there's another row with the exact values in each column\n",
    "dupe = df.duplicated()\n",
    "#duplicate of Jessica, 95; John, 78\n",
    "#returns false on first instance of duplicate row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[dupe]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colA = [10, 20, 40, 50]\n",
    "colB = ['no', 'yes', 'yes', 'no']\n",
    "\n",
    "A_B = list(zip(colA, colB))\n",
    "\n",
    "df_A = pd.DataFrame(data=A_B, columns=['A', 'B'])\n",
    "df_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index = ['a', 'b', 'c', 'd']\n",
    "colA = [10, 20, 40, 50]\n",
    "colB = ['no', 'yes', 'yes', 'no']\n",
    "\n",
    "df_B = pd.DataFrame(data=A_B, columns=['A', 'B'], index=index)\n",
    "\n",
    "df_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loc: label based indexing\n",
    "df_A.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iloc: select row by index(position) number\n",
    "df_A.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#loc: label based indexing\n",
    "df_B.loc['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_B.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's see how it gets tricky\n",
    "df_C = df_A.copy()\n",
    "df_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [2,1,0,3]\n",
    "colA = [10, 20, 40, 50]\n",
    "colB = ['no', 'yes', 'yes', 'no']\n",
    "\n",
    "df_D = pd.DataFrame(data=A_B, columns=['A', 'B'], index=index)\n",
    "df_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#works like python slicing; give me index 0 through the index before 3\n",
    "df_C.iloc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#give me the index label '0' and everything in between and include the label '3'\n",
    "df_C.loc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gave index position 0 through the index position before 3\n",
    "df_D.iloc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gave the label '0' and all the rows that are in between and ending with the row with label '3'\n",
    "df_D.loc[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Code!\n",
    "\n",
    "Below are some code snippets for advanced tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unzip data\n",
    "import zipfile\n",
    "\n",
    "path_to_file = \"datasets.zip\" #file path of zip file\n",
    "extract_directory = \"\"\n",
    "\n",
    "zip_ref = zipfile.ZipFile(path_to_file, 'r')\n",
    "zip_ref.extractall(extract_directory)\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Connect to sqlite db\n",
    "db_file = r'datasets/gradedata.db'\n",
    "engine = create_engine(r\"sqlite:///{}\".format(db_file))\n",
    "\n",
    "sql = \"SELECT * FROM test;\"\n",
    "sales_data_df = pd.read_sql(sql, engine)\n",
    "sales_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find table names\n",
    "sql = \"SELECT name FROM sqlite_master WHERE type = 'table';\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query with conditional\n",
    "sql = 'SELECT * FROM test WHERE Grades IN (76,77,78)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load multiple data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "all_data = pd.DataFrame()\n",
    "for f in glob.glob(\"datasets/data*.xlsx\"):\n",
    "    df = pd.read_excel(f)\n",
    "    all_data = all_data.append(df, ignore_index=True)\n",
    "    \n",
    "all_data.count() #each data file had 100 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "\n",
    "names = ['Bob','Jessica','Mary','John','Mel']\n",
    "\n",
    "random.seed(500)\n",
    "\n",
    "random_names = [names[random.randint(low=0,high=len(names))] \n",
    " \t\t\t\tfor i in range(1000)]\n",
    "\n",
    "births = [random.randint(low=0,high=1000) \n",
    " \t\t  for i in range(1000)]\n",
    "\n",
    "BabyDataSet = list(zip(random_names,births))\n",
    "df = pd.DataFrame(data = BabyDataSet, columns=['Names', 'Births'])\n",
    "\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
